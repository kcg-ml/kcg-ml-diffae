# DiffAE Models List

This document provides a comprehensive overview of the models in the DiffAE repository, including their specifications, inputs, outputs, and related files.

## 1. FFHQ256 Autoencoder

### Model Type
- Diffusion Autoencoder (DiffAE)
- Resolution: 256x256
- Dataset: FFHQ (Flickr-Faces-HQ)

### Inputs
- **x/x_start**: Input images
  - Tensor type: torch.FloatTensor
  - Size: (batch_size, 3, 256, 256)
  - Value range: [-1, 1]
- **t**: Timestep for diffusion process
  - Tensor type: torch.LongTensor
  - Size: (batch_size,)
  - Value range: [0, T] where T is max timesteps (typically 1000)

### Outputs
- **x_pred**: Predicted denoised image
  - Tensor type: torch.FloatTensor
  - Size: (batch_size, 3, 256, 256)
  - Value range: [-1, 1]

### Intermediate Representations
- **xsem/cond**: Semantic encoding from encoder
  - Tensor type: torch.FloatTensor
  - Size: (batch_size, latent_dim)
  - Normalized with mean and std during training
- **xt/x_t**: Noised image at timestep t
  - Tensor type: torch.FloatTensor
  - Size: (batch_size, 3, 256, 256)

### Training Loss
- Diffusion reconstruction loss (L2/MSE)
- Optional perceptual/LPIPS loss

### Files
- **Inference**: 
  - `experiment.py` - Contains `LitModel` class with inference methods
  - Functions: `encode`, `encode_stochastic`, `sample`, `render`
- **Training**:
  - `run_ffhq256.py` - Main training script
  - `run_ffhq256.sh` - Batch script for multi-GPU training
  - `experiment.py` - Contains training step implementation
  - `templates.py` - Contains model configuration (`ffhq256_autoenc()`)

## 2. Other Model Variants
(Based on code references, though less detailed configuration is available)

### FFHQ128 Autoencoder
- Similar to FFHQ256 but at 128x128 resolution
- Training file: `run_ffhq128.py`

### CelebA64 Autoencoder
- Dataset: CelebA
- Resolution: 64x64
- Training file: `run_celeba64.py`

### LSUN Bedroom128 Autoencoder
- Dataset: LSUN Bedroom
- Resolution: 128x128
- Training file: `run_bedroom128.py`

### LSUN Horse128 Autoencoder
- Dataset: LSUN Horse
- Resolution: 128x128
- Training file: `run_horse128.py`

## Tensor Types Summary

| Tensor Name | Description | Size | Value Range |
|-------------|-------------|------|-------------|
| x / x_start | Input images | (B, 3, H, W) | [-1, 1] |
| xt / x_t | Noised images at timestep t | (B, 3, H, W) | Varies with t |
| xsem / cond | Semantic encoding | (B, latent_dim) | Normalized |
| random_x_t | Randomly generated noise | (B, 3, H, W) | Typically N(0,1) |
| t | Diffusion timesteps | (B,) | [0, T] |
| noise | Random noise for sampling | (B, 3, H, W) | N(0,1) |
| pred_img | Generated images | (B, 3, H, W) | [-1, 1] then [0, 1] |

*Note: B = batch size, H = height, W = width*

## Training Modes

1. **Diffusion Mode**
   - Standard diffusion training
   - Works directly with image space

2. **Latent Diffusion Mode**
   - Training on learned latent space
   - Requires pre-trained encoder/decoder